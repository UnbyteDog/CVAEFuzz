#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CVAE è®­ç»ƒä¸»ç¨‹åº
==============

æ”¯æŒé€šè¿‡å‘½ä»¤è¡Œå‚æ•°å¯åŠ¨CVAEè®­ç»ƒ
å¯é€šè¿‡ python main.py --train è§¦å‘

"""

import sys
import os
import argparse
from pathlib import Path

# è§£å†³Windowsä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
if sys.platform.startswith('win'):
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from trainer import CVAETrainer, create_default_config
except ImportError as e:
    print(f"[ERROR] å¯¼å…¥CVAEæ¨¡å—å¤±è´¥ï¼š{e}")
    print("è¯·ç¡®ä¿CVAEæ¨¡å—æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="CVAE æ¨¡å‹è®­ç»ƒå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ï¼š
    python main.py --train
    python main.py --train --epochs 100 --batch-size 64
    python main.py --train --embed-dim 256 --hidden-dim 512
        """
    )

    # è®­ç»ƒå‚æ•°
    parser.add_argument(
        '--train',
        action='store_true',
        help='å¯åŠ¨CVAEæ¨¡å‹è®­ç»ƒ'
    )

    parser.add_argument(
        '--data-path',
        type=str,
        default='../Data/processed/processed_data.pt',
        help='è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ../Data/processed/processed_data.pt)'
    )

    parser.add_argument(
        '--vocab-path',
        type=str,
        default='../Data/processed/vocab.json',
        help='è¯è¡¨æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ../Data/processed/vocab.json)'
    )

    parser.add_argument(
        '--output-dir',
        type=str,
        default='CVAE/checkpoints',
        help='æ¨¡å‹è¾“å‡ºç›®å½• (é»˜è®¤: CVAE/checkpoints)'
    )

    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        '--embed-dim',
        type=int,
        default=128,
        help='è¯åµŒå…¥ç»´åº¦ (é»˜è®¤: 128)'
    )

    parser.add_argument(
        '--hidden-dim',
        type=int,
        default=256,
        help='GRUéšè—å±‚ç»´åº¦ (é»˜è®¤: 256)'
    )

    parser.add_argument(
        '--latent-dim',
        type=int,
        default=32,
        help='éšç©ºé—´ç»´åº¦ (é»˜è®¤: 32)'
    )

    parser.add_argument(
        '--num-layers',
        type=int,
        default=2,
        help='GRUå±‚æ•° (é»˜è®¤: 2)'
    )

    # è®­ç»ƒè¶…å‚æ•°
    parser.add_argument(
        '--epochs',
        type=int,
        default=50,
        help='è®­ç»ƒè½®æ•° (é»˜è®¤: 50)'
    )

    parser.add_argument(
        '--batch-size',
        type=int,
        default=32,
        help='æ‰¹å¤§å° (é»˜è®¤: 32)'
    )

    parser.add_argument(
        '--learning-rate',
        type=float,
        default=1e-3,
        help='å­¦ä¹ ç‡ (é»˜è®¤: 1e-3)'
    )

    parser.add_argument(
        '--weight-decay',
        type=float,
        default=1e-5,
        help='æƒé‡è¡°å‡ (é»˜è®¤: 1e-5)'
    )

    # æ•°æ®å¤„ç†å‚æ•°
    parser.add_argument(
        '--no-oversample',
        action='store_true',
        help='ç¦ç”¨è¿‡é‡‡æ ·'
    )

    parser.add_argument(
        '--train-split',
        type=float,
        default=0.8,
        help='è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤: 0.8)'
    )

    # å…¶ä»–å‚æ•°
    parser.add_argument(
        '--seed',
        type=int,
        default=42,
        help='éšæœºç§å­ (é»˜è®¤: 42)'
    )

    parser.add_argument(
        '--no-amp',
        action='store_true',
        help='ç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒ'
    )

    parser.add_argument(
        '--temperature',
        type=float,
        default=1.0,
        help='Gumbel-Softmaxæ¸©åº¦å‚æ•° (é»˜è®¤: 1.0)'
    )

    parser.add_argument(
        '--kl-cycles',
        type=int,
        default=1,
        help='KLé€€ç«å‘¨æœŸæ•° (é»˜è®¤: 1ï¼Œå•ä¸€ç¨³å®šå¢é•¿)'
    )

    parser.add_argument(
        '--beta-max',
        type=float,
        default=0.25,
        help='KLé€€ç«æœ€å¤§Betaå€¼ (é»˜è®¤: 0.25ï¼Œå¼ºçº¦æŸåŠ›)'
    )

    parser.add_argument(
        '--delay-epochs',
        type=int,
        default=20,
        help='KLé€€ç«å»¶è¿Ÿepochæ•° (é»˜è®¤: 20ï¼Œå…ˆå­¦å¥½é‡æ„)'
    )

    parser.add_argument(
        '--early-stopping',
        action='store_true',
        help='å¯ç”¨æ—©åœ'
    )

    parser.add_argument(
        '--patience',
        type=int,
        default=15,
        help='æ—©åœè€å¿ƒå€¼ (é»˜è®¤: 15)'
    )

    parser.add_argument(
        '--resume',
        type=str,
        help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ'
    )

    parser.add_argument(
        '--generate-samples',
        type=int,
        default=10,
        help='è®­ç»ƒåç”Ÿæˆæ ·æœ¬æ•°é‡ (é»˜è®¤: 10)'
    )

    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º'
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    parser = parse_arguments()

    if not parser.train:
        parser.print_help()
        return

    print("=" * 80)
    print("ğŸ§  CVAE æ¨¡å‹è®­ç»ƒå·¥å…·")
    print("åŸºäº GRU çš„ Seq2Seq æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨")
    print("=" * 80)

    # åˆ›å»ºé…ç½®
    config = create_default_config()

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    config.update({
        'data_path': parser.data_path,
        'vocab_path': parser.vocab_path,
        'output_dir': parser.output_dir,
        'embed_dim': parser.embed_dim,
        'hidden_dim': parser.hidden_dim,
        'latent_dim': parser.latent_dim,
        'num_layers': parser.num_layers,
        'epochs': parser.epochs,
        'batch_size': parser.batch_size,
        'learning_rate': parser.learning_rate,
        'weight_decay': parser.weight_decay,
        'oversample': not parser.no_oversample,
        'train_split': parser.train_split,
        'random_state': parser.seed,
        'use_amp': not parser.no_amp,
        'temperature': parser.temperature,
        'kl_cycles': parser.kl_cycles,
        'early_stopping': parser.early_stopping,
        'patience': parser.patience,
        'verbose': parser.verbose
    })

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    data_path = Path(config['data_path'])
    vocab_path = Path(config['vocab_path'])

    if not data_path.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{data_path}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†ï¼špython main.py --preprocess")
        return

    if not vocab_path.exists():
        print(f"âŒ è¯è¡¨æ–‡ä»¶ä¸å­˜åœ¨ï¼š{vocab_path}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†ï¼špython main.py --preprocess")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(config['output_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)

    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = CVAETrainer(config)

        # ğŸ”¥ æ— æ„Ÿè‡ªåŠ¨æ¢å¤ï¼šå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®š--resumeï¼Œè‡ªåŠ¨æ£€æŸ¥æœ€æ–°æ£€æŸ¥ç‚¹
        if not parser.resume:
            output_dir = Path(config['output_dir'])
            latest_checkpoint = output_dir / 'checkpoint_latest.pth'
            if latest_checkpoint.exists():
                trainer.load_checkpoint(str(latest_checkpoint))
                print(f"ğŸ”„ è‡ªåŠ¨æ¢å¤ï¼šä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
                print(f"ğŸ“‚ æ£€æŸ¥ç‚¹è·¯å¾„ï¼š{latest_checkpoint}")

        # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if parser.resume:
            if Path(parser.resume).exists():
                trainer.load_checkpoint(parser.resume)
                print(f"ğŸ“‚ ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼š{parser.resume}")
            else:
                print(f"âš ï¸ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{parser.resume}ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")

        # å¼€å§‹è®­ç»ƒ
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ CVAE æ¨¡å‹")
        print(f"ğŸ“ æ•°æ®è·¯å¾„ï¼š{config['data_path']}")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•ï¼š{config['output_dir']}")
        print(f"âš™ï¸  æ¨¡å‹é…ç½®ï¼šembed_dim={config['embed_dim']}, hidden_dim={config['hidden_dim']}, latent_dim={config['latent_dim']}")
        print(f"ğŸ¯ è®­ç»ƒé…ç½®ï¼šepochs={config['epochs']}, batch_size={config['batch_size']}, lr={config['learning_rate']}")

        training_history = trainer.train()

        # ç”Ÿæˆæ ·æœ¬
        if parser.generate_samples > 0:
            print(f"\nğŸ² ç”Ÿæˆ {parser.generate_samples} ä¸ªæ ·æœ¬...")
            trainer.generate_samples(num_samples=parser.generate_samples)

        print("\n" + "=" * 80)
        print("ğŸ‰ CVAE è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°ï¼š{config['output_dir']}/cvae.pth")
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        return

    # æ‰“å°æœ€ç»ˆè®­ç»ƒç»Ÿè®¡
    if 'training_history' in locals() and training_history:
        print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡ï¼š")
        best_epoch = min(range(len(training_history)),
                        key=lambda i: training_history[i]['val_metrics']['val_loss'])
        best_metrics = training_history[best_epoch]['val_metrics']

        print(f"   æœ€ä½³ epoch: {best_epoch + 1}")
        print(f"   æœ€ä½³éªŒè¯æŸå¤±: {best_metrics['val_loss']:.4f}")
        print(f"   æœ€ä½³é‡æ„å‡†ç¡®ç‡: {best_metrics['val_recon_accuracy']:.4f}")
        print(f"   æœ€ä½³æœ‰æ•ˆç‡: {best_metrics['val_validity_rate']:.4f}")


if __name__ == "__main__":
    main()